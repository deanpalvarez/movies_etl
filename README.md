# ETL Process using Python with Massive Datasets from Kaggle

Using multiple datasets totalling milllions of rows of film data from Kaggle, we run through the ETL process to clean multiple CSV files containing data that is useful, yet very dirty. Key information such as dates, budgets, and IDs, all vary in format/data type, which is thus made usable through the cleaning/consolidation done in our code.

csv/json files containing the large datasets can be found here:
https://www.sendspace.com/file/byz5ga
